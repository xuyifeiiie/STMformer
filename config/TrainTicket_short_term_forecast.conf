[data]
model=STMFormer
#model=TimesNet
#model=STSGT
#model=MSDR
#model=Informer
#model=Autoformer
#model=FEDformer
#model=PatchTST
#model=STSGCN
#model=GPT4TS
#model=MGT
#model=DLinear
task_name=short_term_forecast
raw_datapath=../data/
processed_datapath=../data/processed/
seed=42
if_scale=True
if_test=False
#if_test=True
batch_size=2
valid_batch_size=4
if_shuffle=True
num_workers=8
num_class=5

# fill_zeros=False

[model]
num_features=80
embed_dim=512
en_in_dim=512
de_in_dim=512
out_layer_dim=512
forward_expansion=512
temporal_emb=False
spatial_emb=False
out_dims=[512, 256, 128, 64, 32, 16, 8]
# [512, 256, 128, 64, 32, 16, 8], [256, 128, 64, 32, 16, 8]
hidden_dims=[[64, 64], [64, 64]]
hidden_dim=64
d_model=512
after_d_model=512
n_heads=8
num_instances=56
num_attention_layers=1
num_en_layers=3
num_de_layers=1
factor=16
# 16
kernels=6
nb_random_features=50
# 64  48  30
nb_gumbel_sample=30
# 48  24  10  5
tau=0.2
# 0.2
rb_order=1
rb_trans=sigmoid
use_edge_loss=False
dropout=0.1
attention=prob
embed=fixed
freq=h
activation=GELU
use_mask=True
if_output_attention=False
decomp=False
decomp_kernels=15
multidecomp=True
multidecomp_kernels=[11, 13, 15]
# 16 steps -> [11, 13, 15], 32 steps  -> [7, 11, 15]
# 64 steps -> [11, 15, 19], 128 steps -> [19, 23, 27]
# 11 13 15 17 19
decomp_stride=1
if_patch=True
distil=False
mix=True
if_wavelet=False
history_steps=16
label_steps=8
predict_steps=16
strides=16

[train]
if_amp=False
seed=42
iters_to_accumulate=10
learning_rate=0.00001
weight_decay=0.0001
lr_decay=True
lr_decay_rate=0.995
if_warmup=True
warmup_steps=500
warmup_lr = 0.00001
epochs=10
co_train=False
print_every=10
save=../checkpoints/train_ticket/
save_limit=4
save_loss=../losses/train_ticket/
expid=16000
max_grad_norm=1
patience=10
log_file=../logs/train_ticket/
if_wandb=True

[test]
log_file=../logs/train_ticket/
test_batch_size=4

